"""
å®Œæ•´æ¨ç†è„šæœ¬
åŠŸèƒ½ï¼š
1. ä½¿ç”¨Stable Diffusionç”Ÿæˆå¸¦æ°´å°çš„å›¾åƒ
2. ä»å›¾åƒä¸­æå–æ°´å°
3. éªŒè¯æ°´å°å®Œæ•´æ€§
"""

import torch
import yaml
from pathlib import Path
import argparse
from PIL import Image
import numpy as np
from typing import List, Union

from sd_pipeline import WatermarkedStableDiffusionPipeline
from models.stage1_codec import PixelNoiseEncoder, PixelNoiseDecoder
from models.stage2_embedder import LatentWatermarkEmbedder
from models.stage2_extractor import PixelWatermarkExtractor
from utils.metrics import WatermarkMetrics


class LatentWOFAInference:
    """
    Latent-WOFAæ¨ç†ç®¡é“
    """
    def __init__(
        self,
        config_path='configs/config.yaml',
        stage1_checkpoint='checkpoints/stage1/best_model.pth',
        stage2_checkpoint='checkpoints/stage2/best_model.pth',
        device='cuda'
    ):
        # åŠ è½½é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ Initializing Latent-WOFA Inference Pipeline on {self.device}")
        
        # 1. åˆå§‹åŒ–Stable Diffusionç®¡é“
        print("\nğŸ“¦ Loading Stable Diffusion pipeline...")
        self.sd_pipeline = WatermarkedStableDiffusionPipeline(
            model_id=self.config['inference']['stable_diffusion_model'],
            vae_model_id=self.config['stage2']['vae_model'],
            device=self.device,
            dtype=torch.float16  # æ¨ç†æ—¶ç”¨float16åŠ é€Ÿ
        )
        
        # 2. åŠ è½½Stage Iæ¨¡å‹
        print("\nğŸ“¦ Loading Stage I models...")
        self.load_stage1_models(stage1_checkpoint)
        
        # 3. åŠ è½½Stage IIæ¨¡å‹
        print("\nğŸ“¦ Loading Stage II models...")
        self.load_stage2_models(stage2_checkpoint)
        
        # 4. å°†æ°´å°æ¨¡å‹æ³¨å…¥SDç®¡é“
        self.sd_pipeline.load_watermark_models(
            embedder=self.embedder,
            extractor=self.extractor,
            stage1_encoder=self.stage1_encoder,
            stage1_decoder=self.stage1_decoder
        )
        
        # 5. åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡
        self.metrics = WatermarkMetrics(device=self.device)
        
        print("\nâœ… Latent-WOFA Inference Pipeline Ready!")
    
    def load_stage1_models(self, checkpoint_path):
        """åŠ è½½Stage Iç¼–è¯‘ç å™¨"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.stage1_encoder = PixelNoiseEncoder(
            num_bits=self.config['watermark']['num_bits'],
            noise_size=self.config['watermark']['noise_size'],
            channels=self.config['stage1']['encoder_channels']
        ).to(self.device)
        
        self.stage1_decoder = PixelNoiseDecoder(
            num_bits=self.config['watermark']['num_bits'],
            noise_size=self.config['watermark']['noise_size'],
            channels=self.config['stage1']['decoder_channels']
        ).to(self.device)
        
        # åŠ è½½æƒé‡
        self.stage1_encoder.load_state_dict(
            {k.replace('encoder.', ''): v for k, v in checkpoint['model_state_dict'].items() 
             if k.startswith('encoder.')}
        )
        self.stage1_decoder.load_state_dict(
            {k.replace('decoder.', ''): v for k, v in checkpoint['model_state_dict'].items() 
             if k.startswith('decoder.')}
        )
        
        self.stage1_encoder.eval()
        self.stage1_decoder.eval()
        
        print("  âœ“ Stage I Encoder loaded")
        print("  âœ“ Stage I Decoder loaded")
    
    def load_stage2_models(self, checkpoint_path):
        """åŠ è½½Stage IIåµŒå…¥å™¨å’Œæå–å™¨"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.embedder = LatentWatermarkEmbedder(self.config).to(self.device)
        self.extractor = PixelWatermarkExtractor(self.config).to(self.device)
        
        self.embedder.load_state_dict(checkpoint['embedder_state_dict'])
        self.extractor.load_state_dict(checkpoint['extractor_state_dict'])
        
        self.embedder.eval()
        self.extractor.eval()
        
        print("  âœ“ Stage II Embedder loaded")
        print("  âœ“ Stage II Extractor loaded")
    
    def bits_to_string(self, bits: torch.Tensor) -> str:
        """
        å°†æ¯”ç‰¹ä¸²è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        Args:
            bits: [num_bits] æ¯”ç‰¹å¼ é‡
        Returns:
            bit_string: "010101..." æ ¼å¼çš„å­—ç¬¦ä¸²
        """
        bits_binary = (bits > 0.5).int().cpu().numpy()
        return ''.join(str(b) for b in bits_binary)
    
    def string_to_bits(self, bit_string: str) -> torch.Tensor:
        """
        å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ¯”ç‰¹ä¸²
        Args:
            bit_string: "010101..." æ ¼å¼çš„å­—ç¬¦ä¸²
        Returns:
            bits: [num_bits] æ¯”ç‰¹å¼ é‡
        """
        bits = torch.tensor([int(b) for b in bit_string], dtype=torch.float32)
        return bits
    
    def generate_random_watermark(self) -> torch.Tensor:
        """
        ç”Ÿæˆéšæœºæ°´å°æ¯”ç‰¹ä¸²
        Returns:
            watermark_bits: [1, num_bits]
        """
        num_bits = self.config['watermark']['num_bits']
        watermark_bits = torch.randint(0, 2, (1, num_bits)).float()
        return watermark_bits
    
    @torch.no_grad()
    def generate_with_watermark(
        self,
        prompt: str,
        watermark_bits: Union[torch.Tensor, str, None] = None,
        negative_prompt: str = "",
        num_inference_steps: int = 50,
        guidance_scale: float = 7.5,
        seed: int = None,
        save_path: str = None
    ):
        """
        ç”Ÿæˆå¸¦æ°´å°çš„å›¾åƒ
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            watermark_bits: æ°´å°æ¯”ç‰¹ä¸²ï¼ˆTensoræˆ–å­—ç¬¦ä¸²ï¼‰ï¼ŒNoneåˆ™éšæœºç”Ÿæˆ
            negative_prompt: è´Ÿå‘æç¤ºè¯
            num_inference_steps: æ¨ç†æ­¥æ•°
            guidance_scale: CFGå¼ºåº¦
            seed: éšæœºç§å­
            save_path: ä¿å­˜è·¯å¾„
        Returns:
            image: PIL Image
            watermark_bits: ä½¿ç”¨çš„æ°´å°æ¯”ç‰¹ä¸²
        """
        print(f"\nğŸ¨ Generating image with watermark...")
        print(f"   Prompt: {prompt}")
        
        # å¤„ç†æ°´å°
        if watermark_bits is None:
            watermark_bits = self.generate_random_watermark()
            print(f"   Generated random watermark")
        elif isinstance(watermark_bits, str):
            watermark_bits = self.string_to_bits(watermark_bits).unsqueeze(0)
        
        watermark_bits = watermark_bits.to(self.device)
        watermark_string = self.bits_to_string(watermark_bits[0])
        print(f"   Watermark: {watermark_string[:20]}... ({len(watermark_string)} bits)")
        
        # ç”Ÿæˆ
        images = self.sd_pipeline.generate_with_watermark(
            prompt=prompt,
            watermark_bits=watermark_bits,
            negative_prompt=negative_prompt,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            seed=seed
        )
        
        image = images[0]
        
        # ä¿å­˜
        if save_path:
            image.save(save_path)
            print(f"   ğŸ’¾ Saved to: {save_path}")
        
        print("   âœ… Generation complete!")
        
        return image, watermark_bits
    
    @torch.no_grad()
    def extract_watermark(
        self,
        image: Union[Image.Image, str, List[Image.Image]],
        true_watermark: torch.Tensor = None
    ):
        """
        ä»å›¾åƒä¸­æå–æ°´å°
        Args:
            image: PIL Image, å›¾åƒè·¯å¾„, æˆ–å›¾åƒåˆ—è¡¨
            true_watermark: çœŸå®æ°´å°ï¼ˆç”¨äºéªŒè¯ï¼‰
        Returns:
            extracted_bits: æå–çš„æ°´å°æ¯”ç‰¹ä¸²
            metrics: è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæä¾›äº†true_watermarkï¼‰
        """
        print(f"\nğŸ” Extracting watermark from image...")
        
        # åŠ è½½å›¾åƒ
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
            print(f"   Loaded image from: {image}")
        
        # æå–
        extracted_bits = self.sd_pipeline.extract_watermark(image)
        extracted_string = self.bits_to_string(extracted_bits[0])
        
        print(f"   Extracted: {extracted_string[:20]}... ({len(extracted_string)} bits)")
        
        # éªŒè¯
        metrics = None
        if true_watermark is not None:
            bit_acc = self.metrics.bit_accuracy(extracted_bits, true_watermark)
            ber = self.metrics.bit_error_rate(extracted_bits, true_watermark)
            
            metrics = {
                'bit_accuracy': bit_acc,
                'bit_error_rate': ber
            }
            
            print(f"\n   ğŸ“Š Verification:")
            print(f"      Bit Accuracy: {bit_acc:.4f} ({bit_acc*100:.2f}%)")
            print(f"      Bit Error Rate: {ber:.4f}")
            
            if bit_acc > 0.95:
                print(f"      âœ… Watermark verified successfully!")
            elif bit_acc > 0.80:
                print(f"      âš ï¸  Watermark partially damaged")
            else:
                print(f"      âŒ Watermark severely damaged")
        
        return extracted_bits, metrics
    
    def demo(self):
        """
        æ¼”ç¤ºå®Œæ•´æµç¨‹ï¼šç”Ÿæˆ â†’ ä¿å­˜ â†’ æå– â†’ éªŒè¯
        """
        print("\n" + "="*60)
        print("Latent-WOFA Demo")
        print("="*60)
        
        # 1. ç”Ÿæˆå¸¦æ°´å°çš„å›¾åƒ
        prompt = "a beautiful landscape with mountains and lake, sunset, highly detailed"
        image, watermark = self.generate_with_watermark(
            prompt=prompt,
            seed=42,
            save_path="output_watermarked.png"
        )
        
        # 2. ä»ç”Ÿæˆçš„å›¾åƒä¸­æå–æ°´å°
        extracted_bits, metrics = self.extract_watermark(
            image=image,
            true_watermark=watermark
        )
        
        print("\n" + "="*60)
        print("Demo Complete!")
        print("="*60)


def main():
    parser = argparse.ArgumentParser(description='Latent-WOFA Inference')
    parser.add_argument('--config', type=str, default='configs/config.yaml',
                       help='Path to config file')
    parser.add_argument('--stage1_ckpt', type=str, default='checkpoints/stage1/best_model.pth',
                       help='Path to Stage I checkpoint')
    parser.add_argument('--stage2_ckpt', type=str, default='checkpoints/stage2/best_model.pth',
                       help='Path to Stage II checkpoint')
    parser.add_argument('--mode', type=str, choices=['generate', 'extract', 'demo'],
                       default='demo', help='Operation mode')
    parser.add_argument('--prompt', type=str, default='a photo of a cat',
                       help='Text prompt for generation')
    parser.add_argument('--image', type=str, help='Image path for extraction')
    parser.add_argument('--output', type=str, default='output.png',
                       help='Output image path')
    parser.add_argument('--seed', type=int, default=None, help='Random seed')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†ç®¡é“
    pipeline = LatentWOFAInference(
        config_path=args.config,
        stage1_checkpoint=args.stage1_ckpt,
        stage2_checkpoint=args.stage2_ckpt
    )
    
    if args.mode == 'generate':
        # ç”Ÿæˆæ¨¡å¼
        image, watermark = pipeline.generate_with_watermark(
            prompt=args.prompt,
            seed=args.seed,
            save_path=args.output
        )
        print(f"\nâœ… Image saved to: {args.output}")
        
    elif args.mode == 'extract':
        # æå–æ¨¡å¼
        if not args.image:
            raise ValueError("Please provide --image path for extraction")
        extracted_bits, _ = pipeline.extract_watermark(image=args.image)
        
    elif args.mode == 'demo':
        # æ¼”ç¤ºæ¨¡å¼
        pipeline.demo()


if __name__ == "__main__":
    main()
