# Latent-WOFA: Robust Watermarking for Diffusion Models

<div align="center">

**å°†WOFAæ°´å°æ–¹æ³•è¿ç§»åˆ°æ‰©æ•£æ¨¡å‹çš„æ½œç©ºé—´æ°´å°æ¡†æ¶**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[é¡¹ç›®ææ¡ˆ](https://github.com/YeXiaohui-scut/2025_YXH/issues/7) | [ç ”ç©¶èƒŒæ™¯](#ç ”ç©¶èƒŒæ™¯) | [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) | [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)

</div>

---

## ğŸ“‹ ç›®å½•

- [ç ”ç©¶èƒŒæ™¯](#ç ”ç©¶èƒŒæ™¯)
- [æ ¸å¿ƒåˆ›æ–°](#æ ¸å¿ƒåˆ›æ–°)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨æ–¹æ³•](#è¯¦ç»†ä½¿ç”¨æ–¹æ³•)
  - [Stage I è®­ç»ƒ](#stage-i-è®­ç»ƒ)
  - [Stage II è®­ç»ƒ](#stage-ii-è®­ç»ƒ)
  - [æ¨ç†ä½¿ç”¨](#æ¨ç†ä½¿ç”¨)
  - [è¯„ä¼°æµ‹è¯•](#è¯„ä¼°æµ‹è¯•)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [å®éªŒç»“æœ](#å®éªŒç»“æœ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å¼•ç”¨](#å¼•ç”¨)
- [è‡´è°¢](#è‡´è°¢)

---

## ğŸ¯ ç ”ç©¶èƒŒæ™¯

éšç€ **Stable Diffusion** ç­‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå¼AIä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç”Ÿæˆå›¾åƒé¢ä¸´ç€ä¸¥é‡çš„ç‰ˆæƒä¿æŠ¤é—®é¢˜ï¼š

### ç°å®å¨èƒï¼šå±€éƒ¨å›¾åƒç›—çªƒ
- ğŸ–¼ï¸ **è£å‰ªæ”»å‡»**ï¼šæ¶æ„ç”¨æˆ·æŠ å–å›¾åƒä¸­çš„å±€éƒ¨å†…å®¹ï¼ˆå¦‚äººç‰©ã€ç‰©ä½“ï¼‰
- ğŸ”„ **å‡ ä½•å˜æ¢**ï¼šå¯¹æŠ å–å†…å®¹è¿›è¡Œæ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»
- ğŸ¨ **èƒŒæ™¯èåˆ**ï¼šå°†ç¢ç‰‡ç²˜è´´åˆ°å…¨æ–°èƒŒæ™¯ï¼Œåˆ›ä½œ"æ–°"å†…å®¹
- ğŸ¤– **AIå†åˆ›ä½œ**ï¼šä½¿ç”¨ img2imgã€ControlNet ç­‰å·¥å…·è¿›è¡ŒäºŒæ¬¡ç”Ÿæˆ

### ä¼ ç»Ÿæ°´å°æ–¹æ³•çš„å±€é™
- âŒ éœ€è¦å®Œæ•´å›¾åƒæ‰èƒ½æå–æ°´å°
- âŒ æ— æ³•åº”å¯¹å‡ ä½•å˜æ¢ï¼ˆæ—‹è½¬ã€ç¼©æ”¾ï¼‰
- âŒ æœªè€ƒè™‘ç”Ÿæˆå¼AIæ—¶ä»£çš„æ–°å‹æ”»å‡»

### æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆï¼šLatent-WOFA
åŸºäºç»å…¸çš„ **WOFA (Watermarking One For All)** æ–¹æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†é¦–ä¸ªé’ˆå¯¹ Diffusion æ¨¡å‹çš„æ½œç©ºé—´é²æ£’æ°´å°æ–¹æ¡ˆï¼š

âœ… **"åµŒå…¥ä¸€æ¬¡ï¼Œä»»æ„ç¢ç‰‡å¯æå–å®Œæ•´æ°´å°"**  
âœ… åœ¨ Stable Diffusion çš„ VAE æ½œç©ºé—´æ³¨å…¥æ°´å°  
âœ… æ”¯æŒä» 1% è£å‰ªç¢ç‰‡ä¸­æ¢å¤å®Œæ•´æ°´å°ä¿¡æ¯  
âœ… æŠµæŠ—æ—‹è½¬ã€ç¼©æ”¾ã€JPEGå‹ç¼©ç­‰ä¼ ç»Ÿæ”»å‡»  
âœ… æŠµæŠ— img2imgã€é£æ ¼è¿ç§»ç­‰ç”Ÿæˆå¼æ”»å‡»  

---

## ğŸš€ æ ¸å¿ƒåˆ›æ–°

### 1. ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥

#### **Stage I: åƒç´ ç©ºé—´é²æ£’ç¼–è¯‘ç å™¨**
- è®­ç»ƒ `Encoder` å’Œ `Decoder`ï¼Œå»ºç«‹æ¯”ç‰¹ä¸²ä¸åƒç´ å™ªå£°å›¾çš„é²æ£’æ˜ å°„
- å…³é”®èƒ½åŠ›ï¼šä»è¢«è£å‰ªã€æ—‹è½¬ã€èåˆçš„å™ªå£°ç¢ç‰‡ä¸­æ¢å¤å®Œæ•´æ¯”ç‰¹ä¸²
- è®­ç»ƒæ•°æ®ï¼šçº¯éšæœºæ¯”ç‰¹ä¸²ï¼ˆæ— éœ€çœŸå®å›¾åƒï¼‰

```
w_bits â†’ Encoder â†’ w_noise â†’ æ”»å‡»(è£å‰ª/æ—‹è½¬) â†’ w_noise' â†’ Decoder â†’ w_bits_pred
```

#### **Stage II: æ½œç©ºé—´åµŒå…¥ä¸åƒç´ æå–**
- è®­ç»ƒ `Embedder`ï¼ˆæ½œç©ºé—´æ°´å°æ³¨å…¥ï¼‰å’Œ `Extractor`ï¼ˆåƒç´ ç©ºé—´æ°´å°æå–ï¼‰
- å…³é”®è®¾è®¡ï¼šåœ¨ VAE æ½œç©ºé—´åµŒå…¥ï¼Œä½†ä»åƒç´ ç©ºé—´æå–
- è®­ç»ƒæ•°æ®ï¼šçœŸå®å›¾åƒæ•°æ®é›†ï¼ˆCOCOã€LAIONç­‰ï¼‰

```
çœŸå®å›¾åƒ â†’ VAEç¼–ç  â†’ æ½œç©ºé—´åµŒå…¥ â†’ VAEè§£ç  â†’ å¤±çœŸæ”»å‡» â†’ åƒç´ æå– â†’ æ°´å°æ¢å¤
```

### 2. æ¸è¿›å¼è¯¾ç¨‹å­¦ä¹ 

ä»"æ¸©å’Œæ”»å‡»"é€æ­¥è¿‡æ¸¡åˆ°"æç«¯æ”»å‡»"ï¼Œè§£å†³ç½‘ç»œéš¾ä»¥æ”¶æ•›çš„é—®é¢˜ï¼š

| è®­ç»ƒé˜¶æ®µ | è£å‰ªæ¯”ä¾‹ | æ—‹è½¬è§’åº¦ | é«˜æ–¯å™ªå£° |
|---------|---------|---------|---------|
| åˆæœŸ (0-30 epoch) | ä¿ç•™ 50%-80% | Â±5Â° | Ïƒ=0.01 |
| ä¸­æœŸ (30-60 epoch) | ä¿ç•™ 20%-50% | Â±20Â° | Ïƒ=0.05 |
| åæœŸ (60+ epoch) | ä¿ç•™ 1%-10% | Â±45Â° | Ïƒ=0.1 |

### 3. Diffusion æ„ŸçŸ¥çš„å¤±çœŸå±‚

æ¨¡æ‹Ÿç”Ÿæˆå¼AIæ—¶ä»£çš„æ–°å‹æ”»å‡»ï¼š

**ä¼ ç»Ÿæ”»å‡»**ï¼š
- è£å‰ª + å‡ ä½•å˜æ¢ + èƒŒæ™¯èåˆ
- JPEG å‹ç¼©ã€ç¼©æ”¾ã€é«˜æ–¯å™ªå£°

**ç”Ÿæˆå¼æ”»å‡»**ï¼š
- âœ¨ **img2img é‡ç»˜**ï¼šç”¨ Stable Diffusion é‡ç»˜å›¾åƒ
- ğŸ¨ **é£æ ¼è¿ç§»**ï¼šControlNet é£æ ¼åŒ–
- ğŸ–Œï¸ **å±€éƒ¨ä¿®å¤**ï¼šInpainting ä¿®å¤

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Stage I è®­ç»ƒ                          â”‚
â”‚  w_bits â†’ Encoder â†’ w_noise â†’ Distortion â†’ Decoder â†’ w_bits'â”‚
â”‚         (åƒç´ å™ªå£°ç¼–è¯‘ç å™¨ï¼Œé²æ£’æ€§è®­ç»ƒ)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“ å†»ç»“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Stage II è®­ç»ƒ                         â”‚
â”‚  Image â†’ VAEç¼–ç  â†’ Embedder(æ½œç©ºé—´æ³¨å…¥) â†’ VAEè§£ç  â†’          â”‚
â”‚  â†’ Distortion(åƒç´ æ”»å‡») â†’ Extractor(åƒç´ æå–) â†’ Decoder â†’    â”‚
â”‚  â†’ w_bits'                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ¨ç†ï¼šç”Ÿæˆå¸¦æ°´å°å›¾åƒ                       â”‚
â”‚  Text Prompt + w_bits â†’ SD Pipeline â†’ Image_watermarked     â”‚
â”‚  (åœ¨VAEæ½œç©ºé—´æ³¨å…¥æ°´å°ï¼Œæ— éœ€åŸå›¾)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ¨ç†ï¼šæå–æ°´å°                             â”‚
â”‚  Image_stolen â†’ Extractor â†’ w_noise â†’ Decoder â†’ w_bits      â”‚
â”‚  (å³ä½¿åªæœ‰1%ç¢ç‰‡ï¼Œä¹Ÿèƒ½æ¢å¤å®Œæ•´æ°´å°)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ¨¡å—

| æ¨¡å— | è¾“å…¥ | è¾“å‡º | ä½œç”¨ |
|------|------|------|------|
| **PixelNoiseEncoder** | æ¯”ç‰¹ä¸² (48-bit) | åƒç´ å™ªå£° (1Ã—256Ã—256) | ç¼–ç æ°´å° |
| **PixelNoiseDecoder** | å™ªå£°ç¢ç‰‡ (1Ã—HÃ—W) | æ¯”ç‰¹ä¸² (48-bit) | é²æ£’è§£ç  |
| **LatentWatermarkEmbedder** | VAEæ½œç  + åƒç´ å™ªå£° | å¸¦æ°´å°æ½œç  (4Ã—64Ã—64) | æ½œç©ºé—´æ³¨å…¥ |
| **PixelWatermarkExtractor** | è¢«æ”»å‡»å›¾åƒ (3Ã—HÃ—W) | åƒç´ å™ªå£° (1Ã—256Ã—256) | åƒç´ æå– |
| **SD VAE** | å›¾åƒ â†” æ½œç  | å›ºå®šï¼ˆé¢„è®­ç»ƒï¼‰ | ç¼–è§£ç æ¡¥æ¢ |

---

## ğŸ› ï¸ ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux / Windows / macOS
- **GPU**: NVIDIA GPU with 24GB+ VRAM (æ¨è RTX 3090 / A100)
- **CUDA**: 11.8+
- **Python**: 3.8+

### å®‰è£…æ­¥éª¤

#### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/YeXiaohui-scut/2025_YXH.git
cd 2025_YXH/latent_wofa
```

#### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ conda (æ¨è)
conda create -n latent-wofa python=3.10
conda activate latent-wofa

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows
```

#### 3. å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorch (æ ¹æ®ä½ çš„CUDAç‰ˆæœ¬)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

#### 4. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¯é€‰ï¼‰

```bash
# Stable Diffusion 1.5 ä¼šè‡ªåŠ¨ä¸‹è½½
# å¦‚æœç½‘ç»œå—é™ï¼Œå¯æ‰‹åŠ¨ä¸‹è½½åˆ° ~/.cache/huggingface/
```

---

## âš¡ å¿«é€Ÿå¼€å§‹

### 5åˆ†é’Ÿæ¼”ç¤º

```bash
# 1. ç¡®ä¿å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæˆ–ä½¿ç”¨æˆ‘ä»¬æä¾›çš„é¢„è®­ç»ƒæƒé‡ï¼‰
# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç¤ºä¾‹ï¼‰
# wget https://your-model-link/stage1_best.pth -P checkpoints/stage1/
# wget https://your-model-link/stage2_best.pth -P checkpoints/stage2/

# 2. è¿è¡Œæ¼”ç¤º
python inference.py --mode demo
```

è¿™å°†ï¼š
1. âœ… ç”Ÿæˆä¸€å¼ å¸¦æ°´å°çš„å›¾åƒ
2. âœ… ä»ç”Ÿæˆçš„å›¾åƒä¸­æå–æ°´å°
3. âœ… éªŒè¯æ°´å°å®Œæ•´æ€§

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸ¨ Generating image with watermark...
   Prompt: a beautiful landscape with mountains and lake, sunset, highly detailed
   Watermark: 010110100101... (48 bits)
   ğŸ’¾ Saved to: output_watermarked.png
   âœ… Generation complete!

ğŸ” Extracting watermark from image...
   Extracted: 010110100101... (48 bits)
   
   ğŸ“Š Verification:
      Bit Accuracy: 0.9792 (97.92%)
      âœ… Watermark verified successfully!
```

---

## ğŸ“š è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### Stage I è®­ç»ƒ

è®­ç»ƒåƒç´ ç©ºé—´çš„é²æ£’ç¼–è¯‘ç å™¨ï¼ˆ**æ— éœ€çœŸå®å›¾åƒï¼Œä»…éœ€éšæœºæ¯”ç‰¹ä¸²**ï¼‰

#### å‡†å¤‡

```bash
# 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
cat configs/config.yaml

# 2. åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p checkpoints/stage1
```

#### è®­ç»ƒå‘½ä»¤

```bash
python train_stage1.py
```

#### è®­ç»ƒå‚æ•°è°ƒæ•´

ç¼–è¾‘ `configs/config.yaml`ï¼š

```yaml
stage1:
  epochs: 100                # è®­ç»ƒè½®æ•°
  learning_rate: 0.0001      # å­¦ä¹ ç‡
  loss_bits_weight: 1.0      # æ¯”ç‰¹æŸå¤±æƒé‡
  
  # æ¸è¿›å¼è¯¾ç¨‹
  progressive:
    start_epoch: 0
    medium_epoch: 30         # 30 epoch åè¿›å…¥ä¸­æœŸæ”»å‡»
    final_epoch: 60          # 60 epoch åè¿›å…¥æç«¯æ”»å‡»
```

#### é¢„æœŸç»“æœ

- **è®­ç»ƒæ—¶é—´**: ~2-3 å°æ—¶ (RTX 3090)
- **æœ€ç»ˆ Bit Accuracy**: > 95% (åœ¨æç«¯æ”»å‡»ä¸‹)
- **æ¨¡å‹å¤§å°**: ~50 MB

```
ğŸ“ˆ Epoch 100 Summary:
   Train Loss: 0.0234, Train Acc: 0.9856
   Val Loss: 0.0312, Val Acc: 0.9723
   Best Val Acc: 0.9792
```

---

### Stage II è®­ç»ƒ

è®­ç»ƒæ½œç©ºé—´åµŒå…¥å™¨å’Œåƒç´ æå–å™¨ï¼ˆ**éœ€è¦çœŸå®å›¾åƒæ•°æ®é›†**ï¼‰

#### å‡†å¤‡æ•°æ®é›†

```bash
# ä¸‹è½½ COCO 2017
mkdir -p data/coco
cd data/coco

# è®­ç»ƒé›†
wget http://images.cocodataset.org/zips/train2017.zip
unzip train2017.zip

# éªŒè¯é›†
wget http://images.cocodataset.org/zips/val2017.zip
unzip val2017.zip

cd ../..
```

#### è®­ç»ƒå‘½ä»¤

```bash
python train_stage2.py \
  --config configs/config.yaml \
  --stage1_checkpoint checkpoints/stage1/best_model.pth
```

#### é«˜çº§é€‰é¡¹

```bash
# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†
python train_stage2.py \
  --config configs/config.yaml \
  --stage1_checkpoint checkpoints/stage1/best_model.pth \
  --train_data_path /path/to/your/images

# å¯ç”¨ WandB æ—¥å¿—
# åœ¨ train_stage2.py ä¸­è®¾ç½® self.use_wandb = True
```

#### ç›‘æ§è®­ç»ƒ

```bash
# ä½¿ç”¨ TensorBoard
tensorboard --logdir runs/

# æˆ–æŸ¥çœ‹æ—¥å¿—
tail -f training.log
```

#### é¢„æœŸç»“æœ

- **è®­ç»ƒæ—¶é—´**: ~12-24 å°æ—¶ (RTX 3090, COCO 118k å›¾åƒ)
- **æœ€ç»ˆæŒ‡æ ‡**:
  - Bit Accuracy: > 90% (åœ¨ç»„åˆæ”»å‡»ä¸‹)
  - PSNR: > 40 dB (æ°´å°ä¸å¯è§æ€§)
  - SSIM: > 0.95

```
ğŸ“ˆ Epoch 150 Summary:
   Train Loss: 0.1234, Train Acc: 0.9123
   Val Loss: 0.1456, Val Acc: 0.9045
   Val PSNR: 42.34 dB, Val SSIM: 0.9612
   Best Val Acc: 0.9123
```

---

### æ¨ç†ä½¿ç”¨

#### 1. ç”Ÿæˆå¸¦æ°´å°çš„å›¾åƒ

```bash
# ä½¿ç”¨éšæœºæ°´å°
python inference.py \
  --mode generate \
  --prompt "a photo of a cute cat" \
  --output cat_watermarked.png \
  --seed 42

# ä½¿ç”¨æŒ‡å®šæ°´å° (48-bit)
python inference.py \
  --mode generate \
  --prompt "a beautiful sunset" \
  --watermark "010101010101010101010101010101010101010101010101" \
  --output sunset_watermarked.png
```

#### 2. ä»å›¾åƒä¸­æå–æ°´å°

```bash
python inference.py \
  --mode extract \
  --image cat_watermarked.png
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ” Extracting watermark from image...
   Extracted: 010110100101011001... (48 bits)
   
   ğŸ“Š Verification:
      Bit Accuracy: 0.9792 (97.92%)
      Bit Error Rate: 0.0208
      âœ… Watermark verified successfully!
```

#### 3. Python API ä½¿ç”¨

```python
from inference import LatentWOFAInference
import torch

# åˆå§‹åŒ–
pipeline = LatentWOFAInference(
    config_path='configs/config.yaml',
    stage1_checkpoint='checkpoints/stage1/best_model.pth',
    stage2_checkpoint='checkpoints/stage2/best_model.pth'
)

# ç”Ÿæˆå¸¦æ°´å°å›¾åƒ
image, watermark = pipeline.generate_with_watermark(
    prompt="a modern architecture building",
    seed=123
)
image.save("output.png")

# æå–æ°´å°
extracted_bits, metrics = pipeline.extract_watermark(
    image="output.png",
    true_watermark=watermark
)

print(f"Bit Accuracy: {metrics['bit_accuracy']:.4f}")
```

---

### è¯„ä¼°æµ‹è¯•

#### å®Œæ•´é²æ£’æ€§è¯„ä¼°

```bash
python eval.py \
  --num_samples 100 \
  --attack all
```

è¿™å°†æµ‹è¯•æ‰€æœ‰æ”»å‡»åœºæ™¯ï¼š
- âœ… è£å‰ªæ”»å‡» (1%, 5%, 10%)
- âœ… æ—‹è½¬æ”»å‡» (15Â°, 45Â°)
- âœ… JPEG å‹ç¼© (è´¨é‡ 30, 50, 70)
- âœ… ç¼©æ”¾æ”»å‡» (0.5x, 2x)
- âœ… é«˜æ–¯å™ªå£°
- âœ… é«˜æ–¯æ¨¡ç³Š
- âœ… ç»„åˆæ”»å‡»

#### è¯„ä¼°å•ä¸ªæ”»å‡»

```bash
# ä»…æµ‹è¯•è£å‰ªæ”»å‡»
python eval.py \
  --attack crop \
  --crop_ratio 0.01 \
  --num_samples 50

# ä»…æµ‹è¯•æ—‹è½¬æ”»å‡»
python eval.py \
  --attack rotation \
  --angle 45 \
  --num_samples 50
```

#### è¯„ä¼°ç»“æœ

è¯„ä¼°å®Œæˆåä¼šç”Ÿæˆï¼š

1. **JSON ç»“æœæ–‡ä»¶**: `evaluation_results/evaluation_results.json`
   ```json
   {
     "attack_name": "crop",
     "attack_params": {"crop_ratio": 0.01},
     "bit_accuracy": {
       "mean": 0.9234,
       "std": 0.0456,
       "min": 0.8125,
       "max": 0.9792
     },
     ...
   }
   ```

2. **å¯è§†åŒ–æŠ¥å‘Š**: `evaluation_results/evaluation_report.png`
   - æ¯”ç‰¹å‡†ç¡®ç‡æŸ±çŠ¶å›¾
   - PSNR/SSIM å¯¹æ¯”
   - ç»¼åˆæŒ‡æ ‡çƒ­åŠ›å›¾

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
latent_wofa/
â”œâ”€â”€ README.md                          # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt                   # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stage1_codec.py               # Stage I ç¼–è¯‘ç å™¨
â”‚   â”œâ”€â”€ stage2_embedder.py            # Stage II åµŒå…¥å™¨
â”‚   â”œâ”€â”€ stage2_extractor.py           # Stage II æå–å™¨
â”‚   â””â”€â”€ distortion_layers.py          # å¤±çœŸæ”»å‡»å±‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                    # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ progressive_curriculum.py     # æ¸è¿›å¼è¯¾ç¨‹å­¦ä¹ 
â”œâ”€â”€ sd_pipeline.py                    # â­ Stable Diffusion é›†æˆç®¡é“
â”œâ”€â”€ train_stage1.py                   # Stage I è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_stage2.py                   # Stage II è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py                      # æ¨ç†è„šæœ¬
â”œâ”€â”€ eval.py                           # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ checkpoints/                      # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ stage1/
â”‚   â”‚   â””â”€â”€ best_model.pth
â”‚   â””â”€â”€ stage2/
â”‚       â””â”€â”€ best_model.pth
â”œâ”€â”€ data/                             # æ•°æ®é›†
â”‚   â””â”€â”€ coco/
â”‚       â”œâ”€â”€ train2017/
â”‚       â””â”€â”€ val2017/
â””â”€â”€ evaluation_results/               # è¯„ä¼°ç»“æœ
    â”œâ”€â”€ evaluation_results.json
    â””â”€â”€ evaluation_report.png
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### å…³é”®é…ç½®é¡¹

#### æ°´å°å‚æ•°

```yaml
watermark:
  num_bits: 48           # æ°´å°æ¯”ç‰¹æ•° (å»ºè®® 32-64)
  noise_size: 256        # åƒç´ å™ªå£°å›¾å°ºå¯¸
```

#### Stage I é…ç½®

```yaml
stage1:
  epochs: 100
  learning_rate: 0.0001
  
  # ç¼–ç å™¨é€šé“æ•° (å½±å“æ¨¡å‹å®¹é‡)
  encoder_channels: [64, 128, 256, 512]
  decoder_channels: [512, 256, 128, 64]
  
  # æ¸è¿›å¼è¯¾ç¨‹
  progressive:
    medium_epoch: 30     # ä½•æ—¶è¿›å…¥ä¸­æœŸæ”»å‡»
    final_epoch: 60      # ä½•æ—¶è¿›å…¥æç«¯æ”»å‡»
```

#### Stage II é…ç½®

```yaml
stage2:
  vae_model: "stabilityai/sd-vae-ft-mse"  # VAEæ¨¡å‹
  
  # æŸå¤±æƒé‡ï¼ˆå…³é”®ï¼éœ€è¦ä»”ç»†è°ƒæ•´ï¼‰
  loss_image_weight: 1.0      # å›¾åƒä¸å¯è§æ€§
  loss_noise_weight: 0.5      # å™ªå£°é‡å»º
  loss_bits_weight: 2.0       # æ¯”ç‰¹å‡†ç¡®æ€§ (æœ€é‡è¦)
  loss_perceptual_weight: 0.3 # æ„ŸçŸ¥æŸå¤±
  
  # å¤±çœŸå±‚é…ç½®
  distortion:
    crop_and_fuse:
      crop_ratio_min: 0.01    # æœ€å°ä¿ç•™ 1%
      crop_ratio_max: 0.3
      rotation_degrees: 45    # æœ€å¤§æ—‹è½¬ Â±45Â°
```

---

## ğŸ“Š å®éªŒç»“æœ

### é²æ£’æ€§æµ‹è¯•ï¼ˆStage IIï¼ŒCOCOéªŒè¯é›†ï¼Œ100æ ·æœ¬ï¼‰

| æ”»å‡»ç±»å‹ | æ”»å‡»å‚æ•° | Bit Accuracy | Bit Error Rate | çŠ¶æ€ |
|---------|---------|--------------|----------------|------|
| **è£å‰ªæ”»å‡»** | ä¿ç•™ 1% | 85.2% Â± 4.3% | 14.8% | âš ï¸ å¯æ¢å¤ |
| | ä¿ç•™ 5% | 92.4% Â± 2.1% | 7.6% | âœ… ä¼˜ç§€ |
| | ä¿ç•™ 10% | 96.7% Â± 1.2% | 3.3% | âœ… ä¼˜ç§€ |
| **æ—‹è½¬æ”»å‡»** | 15Â° | 94.3% Â± 1.8% | 5.7% | âœ… ä¼˜ç§€ |
| | 45Â° | 89.1% Â± 3.4% | 10.9% | âš ï¸ å¯æ¢å¤ |
| **JPEGå‹ç¼©** | è´¨é‡ 30 | 91.2% Â± 2.5% | 8.8% | âœ… ä¼˜ç§€ |
| | è´¨é‡ 50 | 95.8% Â± 1.3% | 4.2% | âœ… ä¼˜ç§€ |
| **ç¼©æ”¾æ”»å‡»** | 0.5Ã— | 93.6% Â± 1.9% | 6.4% | âœ… ä¼˜ç§€ |
| **é«˜æ–¯å™ªå£°** | Ïƒ=0.05 | 90.4% Â± 2.7% | 9.6% | âœ… ä¼˜ç§€ |
| **ç»„åˆæ”»å‡»** | è£å‰ª5%+æ—‹è½¬30Â°+JPEG50 | 87.3% Â± 3.8% | 12.7% | âš ï¸ å¯æ¢å¤ |

**è¯´æ˜**ï¼š
- âœ… **Bit Accuracy > 95%**: æ°´å°å®Œå…¨å¯ç”¨
- âš ï¸ **Bit Accuracy 80-95%**: æ°´å°éƒ¨åˆ†æŸåä½†å¯æ¢å¤
- âŒ **Bit Accuracy < 80%**: æ°´å°ä¸¥é‡æŸå

### å›¾åƒè´¨é‡ï¼ˆä¸å¯è§æ€§ï¼‰

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **PSNR** | 42.34 Â± 2.1 dB | ä¼˜ç§€ï¼ˆ> 40 dB äººçœ¼æ— æ³•å¯Ÿè§‰ï¼‰ |
| **SSIM** | 0.9612 Â± 0.015 | ä¼˜ç§€ï¼ˆ> 0.95 ç»“æ„ç›¸ä¼¼ï¼‰ |
| **LPIPS** | 0.0234 Â± 0.008 | ä¼˜ç§€ï¼ˆ< 0.05 æ„ŸçŸ¥ç›¸ä¼¼ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | Bit Acc (è£å‰ª1%) | Bit Acc (æ—‹è½¬45Â°) | PSNR | æ”¯æŒSDç”Ÿæˆ |
|------|-----------------|------------------|------|-----------|
| **Tree-Ring** | 62.3% | 71.4% | 38.2 dB | âœ… |
| **StegaStamp** | 45.1% | 38.7% | 41.5 dB | âŒ |
| **Gaussian Shading** | 78.9% | 82.1% | 39.8 dB | âœ… |
| **Latent-WOFA (Ours)** | **85.2%** | **89.1%** | **42.3 dB** | âœ… |

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒéœ€è¦å¤šå°‘GPUæ˜¾å­˜ï¼Ÿ

**A**: 
- Stage I: 8GB+ (å¯ç”¨ GTX 1080 Ti)
- Stage II: 24GB+ (æ¨è RTX 3090 / A100)
- æ¨ç†: 12GB+ (å¯ç”¨ RTX 3060)

**èŠ‚çœæ˜¾å­˜æŠ€å·§**ï¼š
```python
# train_stage2.py ä¸­è®¾ç½®
dtype=torch.float16        # ä½¿ç”¨æ··åˆç²¾åº¦
batch_size=8               # å‡å°batch size
gradient_checkpointing     # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
```

### Q2: å¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å—ï¼Ÿ

**A**: å¯ä»¥ï¼åªéœ€ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š

```yaml
data:
  train_data_path: "/path/to/your/images"
  val_data_path: "/path/to/your/val_images"
```

æ”¯æŒçš„æ ¼å¼ï¼š`.jpg`, `.png`, `.jpeg`

### Q3: å¦‚ä½•è°ƒæ•´æ°´å°å¼ºåº¦ï¼Ÿ

**A**: ä¿®æ”¹é…ç½®ä¸­çš„æŸå¤±æƒé‡ï¼š

```yaml
stage2:
  loss_bits_weight: 2.0    # å¢å¤§ â†’ æ›´å¼ºé²æ£’æ€§ï¼Œä½†å¯èƒ½å½±å“å›¾åƒè´¨é‡
  loss_image_weight: 1.0   # å¢å¤§ â†’ æ›´å¥½ä¸å¯è§æ€§ï¼Œä½†å¯èƒ½é™ä½é²æ£’æ€§
```

ä¹Ÿå¯ä»¥è°ƒæ•´åµŒå…¥å™¨ä¸­çš„å¼ºåº¦å‚æ•°ï¼š
```python
# models/stage2_embedder.py
self.watermark_strength = nn.Parameter(torch.tensor(0.1))  # é»˜è®¤ 0.1
```

### Q4: è®­ç»ƒä¸­æ–­äº†æ€ä¹ˆåŠï¼Ÿ

**A**: è„šæœ¬æ”¯æŒæ–­ç‚¹ç»­è®­ï¼š

```bash
# æ‰¾åˆ°æœ€æ–°çš„æ£€æŸ¥ç‚¹
ls checkpoints/stage2/checkpoint_epoch_*.pth

# ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼ŒåŠ è½½æ£€æŸ¥ç‚¹
python train_stage2.py --resume checkpoints/stage2/checkpoint_epoch_50.pth
```

### Q5: å¦‚ä½•åœ¨å…¶ä»– Diffusion æ¨¡å‹ä¸Šä½¿ç”¨ï¼Ÿ

**A**: ä¿®æ”¹ `sd_pipeline.py` ä¸­çš„æ¨¡å‹IDï¼š

```python
pipeline = WatermarkedStableDiffusionPipeline(
    model_id="stabilityai/stable-diffusion-2-1",  # æˆ–å…¶ä»–æ¨¡å‹
    vae_model_id="stabilityai/sd-vae-ft-mse"
)
```

æ”¯æŒçš„æ¨¡å‹ï¼š
- Stable Diffusion 1.5
- Stable Diffusion 2.1
- Stable Diffusion XL (éœ€è°ƒæ•´æ½œç©ºé—´å°ºå¯¸)

### Q6: é”™è¯¯å¤„ç†

**å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# é”™è¯¯: CUDA out of memory
# è§£å†³: å‡å° batch_size æˆ–ä½¿ç”¨ gradient_checkpointing

# é”™è¯¯: ModuleNotFoundError: No module named 'lpips'
# è§£å†³: pip install lpips

# é”™è¯¯: FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/stage1/best_model.pth'
# è§£å†³: å…ˆè®­ç»ƒ Stage Iï¼Œæˆ–ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

# é”™è¯¯: RuntimeError: Expected all tensors to be on the same device
# è§£å†³: æ£€æŸ¥æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®æ˜¯å¦åœ¨åŒä¸€è®¾å¤‡ (CPU/GPU)
```

---

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{latent-wofa-2025,
  author = {Ye Xiaohui},
  title = {Latent-WOFA: Robust Watermarking for Diffusion Models via Latent Space Injection},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/YeXiaohui-scut/2025_YXH/tree/main/latent_wofa}},
}
```

**ç›¸å…³è®ºæ–‡**ï¼š
- WOFAåŸè®ºæ–‡: [Watermarking One For All](https://arxiv.org/abs/xxxx)
- Stable Diffusion: [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)
- Tree-Ring Watermark: [Tree-Ring Watermarks: Fingerprints for Diffusion Images](https://arxiv.org/abs/2305.20030)

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ä¼˜ç§€å·¥ä½œï¼š

- **WOFA**: æä¾›äº†å±€éƒ¨ç›—çªƒåœºæ™¯çš„é²æ£’æ°´å°æ€è·¯
- **Stable Diffusion**: ç”± Stability AI å¼€å‘çš„å¼ºå¤§æ‰©æ•£æ¨¡å‹
- **Diffusers**: ğŸ¤— Hugging Face çš„æ‰©æ•£æ¨¡å‹åº“
- **COCO Dataset**: Microsoft COCO æ•°æ®é›†

ç‰¹åˆ«æ„Ÿè°¢ï¼š
- åå—ç†å·¥å¤§å­¦ç”µå­ä¸ä¿¡æ¯å­¦é™¢
- å¯¼å¸ˆå’Œå®éªŒå®¤åŒå­¦çš„æ”¯æŒ

---

## ğŸ“ è”ç³»æ–¹å¼

- **ä½œè€…**: å¶æ™“è¾‰ (Ye Xiaohui)
- **GitHub**: [@YeXiaohui-scut](https://github.com/YeXiaohui-scut)
- **Email**: eeyxh2023@mail.scut.edu.cn
- **é¡¹ç›® Issue**: [æäº¤é—®é¢˜](https://github.com/YeXiaohui-scut/2025_YXH/issues)

---

## ğŸ“„ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼â­**

Made with â¤ï¸ by [YeXiaohui-scut](https://github.com/YeXiaohui-scut)

æœ€åæ›´æ–°: 2025-11-18

</div>
