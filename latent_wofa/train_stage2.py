"""
Stage II å®Œæ•´è®­ç»ƒè„šæœ¬
è®­ç»ƒæ½œç©ºé—´åµŒå…¥å™¨å’Œåƒç´ ç©ºé—´æå–å™¨
ä½¿ç”¨Stable Diffusionçš„VAEè¿›è¡Œè®­ç»ƒ
"""

import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import numpy as np
from tqdm import tqdm
import wandb
from pathlib import Path
import lpips

from models.stage1_codec import PixelNoiseEncoder, PixelNoiseDecoder
from models.stage2_embedder import LatentWatermarkEmbedder
from models.stage2_extractor import PixelWatermarkExtractor
from models.distortion_layers import Stage2DistortionLayer
from utils.progressive_curriculum import ProgressiveCurriculum
from utils.metrics import WatermarkMetrics
from sd_pipeline import WatermarkedStableDiffusionPipeline


class ImageDataset(Dataset):
    """
    å›¾åƒæ•°æ®é›†ï¼ˆCOCOæˆ–å…¶ä»–ï¼‰
    Stage IIéœ€è¦çœŸå®å›¾åƒæ¥è®­ç»ƒåµŒå…¥å™¨å’Œæå–å™¨
    """
    def __init__(self, data_path, image_size=512, num_samples=None):
        self.data_path = Path(data_path)
        self.image_size = image_size
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        self.image_paths = list(self.data_path.glob('*.jpg')) + \
                          list(self.data_path.glob('*.png'))
        
        if num_samples:
            self.image_paths = self.image_paths[:num_samples]
        
        print(f"Found {len(self.image_paths)} images in {data_path}")
        
        # å›¾åƒå˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # [-1, 1]
        ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        image = self.transform(image)
        
        return image


class Stage2Trainer:
    def __init__(self, config_path='configs/config.yaml', stage1_checkpoint=None):
        # åŠ è½½é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_dir = Path('checkpoints/stage2')
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. åŠ è½½Stage Iè®­ç»ƒå¥½çš„ç¼–è¯‘ç å™¨ï¼ˆå†»ç»“ï¼‰
        print("Loading Stage I models...")
        if stage1_checkpoint is None:
            stage1_checkpoint = 'checkpoints/stage1/best_model.pth'
        
        checkpoint = torch.load(stage1_checkpoint, map_location=self.device)
        
        self.stage1_encoder = PixelNoiseEncoder(
            num_bits=self.config['watermark']['num_bits'],
            noise_size=self.config['watermark']['noise_size'],
            channels=self.config['stage1']['encoder_channels']
        ).to(self.device)
        
        self.stage1_decoder = PixelNoiseDecoder(
            num_bits=self.config['watermark']['num_bits'],
            noise_size=self.config['watermark']['noise_size'],
            channels=self.config['stage1']['decoder_channels']
        ).to(self.device)
        
        # åŠ è½½æƒé‡
        self.stage1_encoder.load_state_dict(
            {k.replace('encoder.', ''): v for k, v in checkpoint['model_state_dict'].items() 
             if k.startswith('encoder.')}
        )
        self.stage1_decoder.load_state_dict(
            {k.replace('decoder.', ''): v for k, v in checkpoint['model_state_dict'].items() 
             if k.startswith('decoder.')}
        )
        
        # å†»ç»“Stage Iæ¨¡å‹
        self.stage1_encoder.eval()
        self.stage1_decoder.eval()
        for param in self.stage1_encoder.parameters():
            param.requires_grad = False
        for param in self.stage1_decoder.parameters():
            param.requires_grad = False
        
        print("âœ… Stage I models loaded and frozen")
        
        # 2. åˆå§‹åŒ–Stable Diffusion VAE
        print("Loading Stable Diffusion VAE...")
        self.sd_pipeline = WatermarkedStableDiffusionPipeline(
            model_id=self.config['inference']['stable_diffusion_model'],
            vae_model_id=self.config['stage2']['vae_model'],
            device=self.device,
            dtype=torch.float32  # è®­ç»ƒæ—¶ç”¨float32
        )
        
        # VAEä¹Ÿå†»ç»“ï¼ˆæˆ‘ä»¬åªç”¨å®ƒåšç¼–è§£ç ï¼‰
        for param in self.sd_pipeline.vae.parameters():
            param.requires_grad = False
        
        print("âœ… SD VAE loaded and frozen")
        
        # 3. åˆå§‹åŒ–Stage IIæ¨¡å‹ï¼ˆéœ€è¦è®­ç»ƒï¼‰
        print("Initializing Stage II models...")
        self.embedder = LatentWatermarkEmbedder(self.config).to(self.device)
        self.extractor = PixelWatermarkExtractor(self.config).to(self.device)
        
        # 4. åˆå§‹åŒ–æ¸è¿›å¼è¯¾ç¨‹å­¦ä¹ 
        self.curriculum = ProgressiveCurriculum(self.config, stage='stage2')
        
        # 5. åˆå§‹åŒ–å¤±çœŸå±‚
        self.distortion_layer = Stage2DistortionLayer(
            self.config,
            progressive_level='initial',
            background_images=None  # å¯ä»¥åŠ è½½èƒŒæ™¯å›¾åƒåº“
        ).to(self.device)
        
        # 6. æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
        self.lpips_loss = lpips.LPIPS(net='alex').to(self.device)
        for param in self.lpips_loss.parameters():
            param.requires_grad = False
        
        # 7. ä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ–embedderå’Œextractorï¼‰
        self.optimizer = optim.Adam(
            list(self.embedder.parameters()) + list(self.extractor.parameters()),
            lr=self.config['stage2']['learning_rate'],
            weight_decay=self.config['stage2']['weight_decay']
        )
        
        # 8. å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=self.config['stage2']['epochs']
        )
        
        # 9. æ•°æ®é›†
        print("Loading datasets...")
        self.train_dataset = ImageDataset(
            data_path=self.config['data']['train_data_path'],
            image_size=self.config['data']['image_size']
        )
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config['data']['batch_size'],
            shuffle=True,
            num_workers=self.config['data']['num_workers'],
            pin_memory=True
        )
        
        self.val_dataset = ImageDataset(
            data_path=self.config['data']['val_data_path'],
            image_size=self.config['data']['image_size'],
            num_samples=500  # éªŒè¯é›†å–500å¼ 
        )
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config['data']['batch_size'],
            shuffle=False,
            num_workers=self.config['data']['num_workers']
        )
        
        # 10. è¯„ä¼°æŒ‡æ ‡
        self.metrics = WatermarkMetrics(device=self.device)
        
        # 11. æŸå¤±æƒé‡
        self.loss_weights = {
            'image': self.config['stage2']['loss_image_weight'],
            'noise': self.config['stage2']['loss_noise_weight'],
            'bits': self.config['stage2']['loss_bits_weight'],
            'perceptual': self.config['stage2']['loss_perceptual_weight']
        }
        
        # 12. WandBåˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰
        self.use_wandb = False  # è®¾ç½®ä¸ºTrueå¯ç”¨
        if self.use_wandb:
            wandb.init(
                project="latent-wofa",
                name="stage2_training",
                config=self.config
            )
    
    def compute_losses(self, I_original, I_watermarked, I_attacked, 
                      w_bits, w_noise, w_noise_pred, w_bits_pred):
        """
        è®¡ç®—æ‰€æœ‰æŸå¤±
        """
        losses = {}
        
        # 1. å›¾åƒä¸å¯è§æ€§æŸå¤±ï¼ˆæ°´å°å›¾åº”è¯¥å’ŒåŸå›¾æ¥è¿‘ï¼‰
        losses['image'] = self.mse_loss(I_watermarked, I_original)
        
        # 2. æ„ŸçŸ¥æŸå¤±ï¼ˆLPIPSï¼‰
        losses['perceptual'] = self.lpips_loss(I_watermarked, I_original).mean()
        
        # 3. å™ªå£°é‡å»ºæŸå¤±ï¼ˆæå–çš„å™ªå£°åº”è¯¥å’ŒåŸå§‹å™ªå£°æ¥è¿‘ï¼‰
        losses['noise'] = self.mse_loss(w_noise_pred, w_noise)
        
        # 4. æ¯”ç‰¹å‡†ç¡®æ€§æŸå¤±ï¼ˆæœ€é‡è¦ï¼‰
        losses['bits'] = self.bce_loss(w_bits_pred, w_bits)
        
        # æ€»æŸå¤±
        total_loss = (
            self.loss_weights['image'] * losses['image'] +
            self.loss_weights['perceptual'] * losses['perceptual'] +
            self.loss_weights['noise'] * losses['noise'] +
            self.loss_weights['bits'] * losses['bits']
        )
        
        losses['total'] = total_loss
        
        return losses
    
    def train_epoch(self, epoch):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        """
        self.embedder.train()
        self.extractor.train()
        
        total_losses = {k: 0.0 for k in ['total', 'image', 'perceptual', 'noise', 'bits']}
        total_bit_acc = 0
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å¤±çœŸå±‚
        if self.curriculum.should_update_distortion(epoch):
            progressive_level = self.curriculum.get_progressive_level(epoch)
            print(f"\nğŸ”„ Updating distortion layer to: {progressive_level}")
            self.distortion_layer = Stage2DistortionLayer(
                self.config,
                progressive_level=progressive_level,
                background_images=None
            ).to(self.device)
        
        progress_bar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}")
        
        for batch_idx, I_original in enumerate(progress_bar):
            I_original = I_original.to(self.device)
            batch_size = I_original.size(0)
            
            # ç”Ÿæˆéšæœºæ°´å°æ¯”ç‰¹ä¸²
            w_bits = torch.randint(0, 2, (batch_size, self.config['watermark']['num_bits'])).float().to(self.device)
            
            # ===== å‰å‘ä¼ æ’­ =====
            
            # 1. ç”¨Stage Iç¼–ç å™¨ç”Ÿæˆåƒç´ å™ªå£°ï¼ˆå†»ç»“ï¼‰
            with torch.no_grad():
                w_noise = self.stage1_encoder(w_bits)  # [B, 1, 256, 256]
            
            # 2. ç”¨VAEç¼–ç åŸå›¾åˆ°æ½œç©ºé—´ï¼ˆå†»ç»“ï¼‰
            with torch.no_grad():
                z_original = self.sd_pipeline.vae.encode(I_original).latent_dist.sample()
                z_original = z_original * 0.18215
            
            # 3. ç”¨embedderåœ¨æ½œç©ºé—´åµŒå…¥æ°´å°ï¼ˆè®­ç»ƒï¼‰
            z_watermarked = self.embedder(z_original, w_noise)
            
            # 4. ç”¨VAEè§£ç å›åƒç´ ç©ºé—´ï¼ˆå†»ç»“ï¼‰
            with torch.no_grad():
                I_watermarked = self.sd_pipeline.decode_latent_to_image(z_watermarked)
            
            # 5. åº”ç”¨å¤±çœŸæ”»å‡»ï¼ˆè®­ç»ƒï¼‰
            I_attacked = self.distortion_layer(I_watermarked)
            
            # 6. ç”¨extractorä»è¢«æ”»å‡»å›¾åƒæå–å™ªå£°ï¼ˆè®­ç»ƒï¼‰
            w_noise_pred = self.extractor(I_attacked)
            
            # 7. ç”¨Stage Iè§£ç å™¨è§£ç æ¯”ç‰¹ä¸²ï¼ˆå†»ç»“ï¼‰
            with torch.no_grad():
                w_bits_pred = self.stage1_decoder(w_noise_pred)
            
            # ===== è®¡ç®—æŸå¤± =====
            losses = self.compute_losses(
                I_original, I_watermarked, I_attacked,
                w_bits, w_noise, w_noise_pred, w_bits_pred
            )
            
            # ===== åå‘ä¼ æ’­ =====
            self.optimizer.zero_grad()
            losses['total'].backward()
            torch.nn.utils.clip_grad_norm_(
                list(self.embedder.parameters()) + list(self.extractor.parameters()),
                max_norm=1.0
            )
            self.optimizer.step()
            
            # ===== ç»Ÿè®¡ =====
            for k in total_losses.keys():
                total_losses[k] += losses[k].item()
            
            bit_acc = self.metrics.bit_accuracy(w_bits_pred, w_bits)
            total_bit_acc += bit_acc
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{losses['total'].item():.4f}",
                'bit_acc': f"{bit_acc:.4f}",
                'psnr': f"{self.metrics.psnr(I_original, I_watermarked):.2f}"
            })
            
            # WandBæ—¥å¿—
            if self.use_wandb and batch_idx % 10 == 0:
                wandb.log({
                    'train/loss_total': losses['total'].item(),
                    'train/loss_image': losses['image'].item(),
                    'train/loss_perceptual': losses['perceptual'].item(),
                    'train/loss_noise': losses['noise'].item(),
                    'train/loss_bits': losses['bits'].item(),
                    'train/bit_accuracy': bit_acc,
                    'epoch': epoch
                })
        
        # è®¡ç®—å¹³å‡å€¼
        num_batches = len(self.train_loader)
        avg_losses = {k: v / num_batches for k, v in total_losses.items()}
        avg_bit_acc = total_bit_acc / num_batches
        
        return avg_losses, avg_bit_acc
    
    @torch.no_grad()
    def validate(self, epoch):
        """
        éªŒè¯
        """
        self.embedder.eval()
        self.extractor.eval()
        
        total_losses = {k: 0.0 for k in ['total', 'image', 'perceptual', 'noise', 'bits']}
        total_bit_acc = 0
        total_psnr = 0
        total_ssim = 0
        
        for I_original in tqdm(self.val_loader, desc="Validation"):
            I_original = I_original.to(self.device)
            batch_size = I_original.size(0)
            
            w_bits = torch.randint(0, 2, (batch_size, self.config['watermark']['num_bits'])).float().to(self.device)
            
            # å‰å‘ä¼ æ’­ï¼ˆä¸è®­ç»ƒç›¸åŒï¼‰
            w_noise = self.stage1_encoder(w_bits)
            z_original = self.sd_pipeline.vae.encode(I_original).latent_dist.sample() * 0.18215
            z_watermarked = self.embedder(z_original, w_noise)
            I_watermarked = self.sd_pipeline.decode_latent_to_image(z_watermarked)
            I_attacked = self.distortion_layer(I_watermarked)
            w_noise_pred = self.extractor(I_attacked)
            w_bits_pred = self.stage1_decoder(w_noise_pred)
            
            # è®¡ç®—æŸå¤±
            losses = self.compute_losses(
                I_original, I_watermarked, I_attacked,
                w_bits, w_noise, w_noise_pred, w_bits_pred
            )
            
            for k in total_losses.keys():
                total_losses[k] += losses[k].item()
            
            # è¯„ä¼°æŒ‡æ ‡
            bit_acc = self.metrics.bit_accuracy(w_bits_pred, w_bits)
            psnr = self.metrics.psnr(I_original, I_watermarked)
            ssim = self.metrics.ssim(I_original, I_watermarked)
            
            total_bit_acc += bit_acc
            total_psnr += psnr
            total_ssim += ssim
        
        # è®¡ç®—å¹³å‡å€¼
        num_batches = len(self.val_loader)
        avg_losses = {k: v / num_batches for k, v in total_losses.items()}
        avg_bit_acc = total_bit_acc / num_batches
        avg_psnr = total_psnr / num_batches
        avg_ssim = total_ssim / num_batches
        
        print(f"\nğŸ“Š Validation Results:")
        print(f"   Loss: {avg_losses['total']:.4f}")
        print(f"   Bit Acc: {avg_bit_acc:.4f}")
        print(f"   PSNR: {avg_psnr:.2f} dB")
        print(f"   SSIM: {avg_ssim:.4f}")
        
        if self.use_wandb:
            wandb.log({
                'val/loss': avg_losses['total'],
                'val/bit_accuracy': avg_bit_acc,
                'val/psnr': avg_psnr,
                'val/ssim': avg_ssim,
                'epoch': epoch
            })
        
        return avg_losses, avg_bit_acc, avg_psnr, avg_ssim
    
    def save_checkpoint(self, epoch, best=False):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹
        """
        checkpoint = {
            'epoch': epoch,
            'embedder_state_dict': self.embedder.state_dict(),
            'extractor_state_dict': self.extractor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'config': self.config
        }
        
        if best:
            save_path = self.save_dir / 'best_model.pth'
            print(f"ğŸ’¾ Saving best model to {save_path}")
        else:
            save_path = self.save_dir / f'checkpoint_epoch_{epoch}.pth'
        
        torch.save(checkpoint, save_path)
    
    def train(self):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        """
        print("\n" + "="*60)
        print("Starting Stage II Training")
        print("="*60)
        print(f"Total epochs: {self.config['stage2']['epochs']}")
        print(f"Batch size: {self.config['data']['batch_size']}")
        print(f"Learning rate: {self.config['stage2']['learning_rate']}")
        print("="*60 + "\n")
        
        best_val_acc = 0.0
        
        for epoch in range(self.config['stage2']['epochs']):
            # æ˜¾ç¤ºå½“å‰è¯¾ç¨‹é˜¶æ®µ
            print(f"\n{self.curriculum.get_description(epoch)}")
            
            # è®­ç»ƒ
            train_losses, train_acc = self.train_epoch(epoch)
            
            # éªŒè¯
            val_losses, val_acc, val_psnr, val_ssim = self.validate(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                self.save_checkpoint(epoch, best=True)
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % 10 == 0:
                self.save_checkpoint(epoch)
            
            print(f"\nğŸ“ˆ Epoch {epoch+1} Summary:")
            print(f"   Train Loss: {train_losses['total']:.4f}, Train Acc: {train_acc:.4f}")
            print(f"   Val Loss: {val_losses['total']:.4f}, Val Acc: {val_acc:.4f}")
            print(f"   Val PSNR: {val_psnr:.2f} dB, Val SSIM: {val_ssim:.4f}")
            print(f"   Best Val Acc: {best_val_acc:.4f}")
            print(f"   Learning Rate: {self.scheduler.get_last_lr()[0]:.6f}")
        
        print("\n" + "="*60)
        print("âœ… Stage II Training Completed!")
        print(f"Best Validation Accuracy: {best_val_acc:.4f}")
        print("="*60)
        
        if self.use_wandb:
            wandb.finish()


if __name__ == "__main__":
    trainer = Stage2Trainer(
        config_path='configs/config.yaml',
        stage1_checkpoint='checkpoints/stage1/best_model.pth'
    )
    trainer.train()
