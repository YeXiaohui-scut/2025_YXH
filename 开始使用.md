# å¼€å§‹ä½¿ç”¨ / Getting Started

## 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹ / 5-Minute Quick Start

### ç¬¬ä¸€æ­¥: æµ‹è¯•ç³»ç»Ÿ / Step 1: Test the System

```bash
# æµ‹è¯•è¯­ä¹‰ç¼–ç  (æ— éœ€ä»»ä½•æ•°æ®)
python examples/train_semantic_example.py --mode test_encoding

# é¢„æœŸè¾“å‡º:
# âœ“ Encoder initialized (dim=512)
# âœ“ Encryption test passed
```

### ç¬¬äºŒæ­¥: æŸ¥çœ‹æç¤ºè¯ç”Ÿæˆ / Step 2: View Prompt Generation

```bash
# æŸ¥çœ‹ç³»ç»Ÿç”Ÿæˆçš„æç¤ºè¯å¤šæ ·æ€§
python examples/train_semantic_example.py --mode demo_prompts

# å°†çœ‹åˆ° 100+ ç§è‡ªåŠ¨ç”Ÿæˆçš„æç¤ºè¯ï¼Œå¦‚:
# - "A photo with natural lighting"
# - "A detailed scene at sunset"
# - "A landscape with vivid colors"
```

### ç¬¬ä¸‰æ­¥: å¿«é€Ÿè®­ç»ƒæ¼”ç¤º / Step 3: Quick Training Demo

```bash
# ä½¿ç”¨æ ·ä¾‹æ•°æ®å¿«é€Ÿæ¼”ç¤ºè®­ç»ƒæµç¨‹ (2 epochs, å‡ åˆ†é’Ÿå®Œæˆ)
python examples/train_semantic_example.py \
    --mode train \
    --use_sample_data \
    --max_epochs 2 \
    --batch_size 4

# è¿™ä¼š:
# - è‡ªåŠ¨åˆ›å»º 20 å¼ æ ·ä¾‹å›¾ç‰‡
# - ç”Ÿæˆæç¤ºè¯
# - è®­ç»ƒ 2 ä¸ª epoch
# - ä¿å­˜æ£€æŸ¥ç‚¹
```

### ç¬¬å››æ­¥: æ­£å¼è®­ç»ƒ / Step 4: Real Training

å‡†å¤‡ä½ çš„æ•°æ®:
```
/data/
  â””â”€â”€ images/
      â”œâ”€â”€ image_001.jpg
      â”œâ”€â”€ image_002.jpg
      â””â”€â”€ ...
```

åˆ›å»ºå›¾ç‰‡åˆ—è¡¨:
```csv
# data/train.csv
path
image_001.jpg
image_002.jpg
...
```

å¼€å§‹è®­ç»ƒ:
```bash
python train.py \
    --config configs/SD14_SemanticLaWa.yaml \
    --batch_size 8 \
    --max_epochs 40 \
    --learning_rate 0.00006 \
    --output results/my_training
```

**æ— éœ€å›¾ç‰‡è¯´æ˜ï¼** ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆæç¤ºè¯ã€‚

## å¦‚æœä½ æœ‰å›¾ç‰‡è¯´æ˜ / If You Have Captions

### å‡†å¤‡è¯´æ˜æ–‡ä»¶ / Prepare Caption File

```csv
# data/captions.csv
path,caption
image_001.jpg,ä¸€å¼ ç¾ä¸½çš„é£æ™¯ç…§
image_002.jpg,ä¸€åªå¯çˆ±çš„çŒ«å’ª
...
```

### æ›´æ–°é…ç½® / Update Config

ç¼–è¾‘ `configs/SD14_SemanticLaWa.yaml`:

```yaml
data:
  params:
    train:
      params:
        caption_file: data/captions.csv  # æ·»åŠ è¿™ä¸€è¡Œ
```

### å¼€å§‹è®­ç»ƒ / Start Training

```bash
python train.py --config configs/SD14_SemanticLaWa.yaml
```

## è®­ç»ƒç›‘æ§ / Training Monitoring

è®­ç»ƒè¿‡ç¨‹ä¸­å…³æ³¨è¿™äº›æŒ‡æ ‡:

```
train/cosine_sim    åº”è¯¥é€æ¸æå‡åˆ° >0.85
train/psnr          åº”è¯¥ä¿æŒ >40 dB
train/emb_loss      åº”è¯¥é€æ¸ä¸‹é™
```

**è¿›åº¦å‚è€ƒ:**
- Epochs 1-10: cosine_sim ä» 0.3 å‡åˆ° 0.6
- Epochs 10-20: cosine_sim ä» 0.6 å‡åˆ° 0.8
- Epochs 20-30: cosine_sim è¾¾åˆ° >0.85 (æ”¶æ•›)

## è®­ç»ƒåä½¿ç”¨ / After Training

### åŠ è½½æ¨¡å‹ / Load Model

```python
from models.semanticLaWa import SemanticLaWa

model = SemanticLaWa.load_from_checkpoint(
    'results/my_training/checkpoints/last.ckpt'
)
```

### ç”Ÿæˆå¸¦æ°´å°å›¾åƒ / Generate Watermarked Image

```python
# ç”¨ç‰¹å®šæç¤ºè¯
prompt = "é¤æ¡Œä¸Šçš„ä¸€ç›˜ç¾é£Ÿ"

# ç¼–ç æç¤ºè¯
semantic_vector = model.semantic_encoder(prompt, encrypt=True)

# ç”Ÿæˆå¸¦æ°´å°å›¾åƒ
watermarked = model(latent, original_image, semantic_vector)
```

### éªŒè¯æ°´å° / Verify Watermark

```python
# æå–æ°´å°
extracted = model.decoder(watermarked)
decrypted = model.semantic_encoder.rotation_matrix.decrypt(extracted)

# éªŒè¯
is_authentic, similarity = model.semantic_encoder.verify(
    decrypted, 
    prompt,
    threshold=0.85
)

print(f"çœŸå®æ€§: {is_authentic}, ç›¸ä¼¼åº¦: {similarity:.4f}")
```

## å¸¸è§ä½¿ç”¨åœºæ™¯ / Common Use Cases

### åœºæ™¯ 1: æ²¡æœ‰å›¾ç‰‡è¯´æ˜ (æœ€ç®€å•)

```bash
# ç›´æ¥è®­ç»ƒï¼Œç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆæç¤ºè¯
python train.py --config configs/SD14_SemanticLaWa.yaml

# æ¯å¼ å›¾ç‰‡è·å¾—éšæœºä½†ä¸€è‡´çš„æç¤ºè¯
# æ°´å°ä»ç„¶æ˜¯å”¯ä¸€çš„
```

### åœºæ™¯ 2: æœ‰å›¾ç‰‡è¯´æ˜

```bash
# å‡†å¤‡ captions.csv
# æ›´æ–°é…ç½®æ·»åŠ  caption_file
# è®­ç»ƒ

# æ¯å¼ å›¾ç‰‡ä½¿ç”¨å…¶çœŸå®è¯´æ˜
# æ°´å°ä¸å†…å®¹è¯­ä¹‰å¼ºç»‘å®š
```

### åœºæ™¯ 3: T2I ç”Ÿæˆ

```python
# ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾åƒæ—¶
prompt = "A beautiful sunset over the ocean"

# ç”¨ç›¸åŒæç¤ºè¯ç”Ÿæˆè¯­ä¹‰æ°´å°
semantic_vec = encoder(prompt, encrypt=True)
watermarked = model(sd_latent, sd_image, semantic_vec)

# æ°´å°è‡ªç„¶ä¸ç”Ÿæˆå†…å®¹å…³è”
```

### åœºæ™¯ 4: æ‰¹é‡æ°´å°

```python
# ä¸ºä¸åŒå›¾ç‰‡ä½¿ç”¨ä¸åŒæç¤ºè¯
prompts = [
    "Photo 1 description",
    "Photo 2 description",
    "Photo 3 description"
]

for img, prompt in zip(images, prompts):
    semantic_vec = encoder(prompt, encrypt=True)
    watermarked = model(encode(img), img, semantic_vec)
    save(watermarked)
```

## æ•…éšœæ’æŸ¥ / Troubleshooting

### é—®é¢˜: ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆä½ (<0.70)

**è§£å†³æ–¹æ¡ˆ:**
```yaml
# å¢åŠ è¯­ä¹‰æŸå¤±æƒé‡
semantic_loss_weight: 3.0  # ä» 2.0 å¢åŠ 

# æˆ–é™ä½å­¦ä¹ ç‡
learning_rate: 0.00004  # ä» 0.00006 é™ä½

# æˆ–è®­ç»ƒæ›´ä¹…
--max_epochs 50
```

### é—®é¢˜: æ°´å°å¤ªæ˜æ˜¾

**è§£å†³æ–¹æ¡ˆ:**
```yaml
# é™ä½æ°´å°å¼ºåº¦
watermark_addition_weight: 0.05  # ä» 0.1 é™ä½

# å¢åŠ é‡å»ºæŸå¤±æƒé‡
recon_loss_weight: 0.2  # ä» 0.1 å¢åŠ 
```

### é—®é¢˜: æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ:**
```yaml
# ä½¿ç”¨è½»é‡çº§ U-Net
use_lightweight_wemb: True

# æˆ–å‡å°æ‰¹é‡å¤§å°
--batch_size 4

# æˆ–å‡å°å›¾åƒå°ºå¯¸
resize: 256
```

### é—®é¢˜: CLIP æ¨¡å‹åŠ è½½å¤±è´¥

**ä¸æ˜¯é—®é¢˜ï¼** ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å“ˆå¸Œåå¤‡æ¨¡å¼:
```
Warning: transformers not installed. Using fallback encoding mode.
```

è¿™æ˜¯æ­£å¸¸çš„ï¼Œè®­ç»ƒä»ç„¶å¯ä»¥è¿›è¡Œã€‚å¦‚æœæƒ³ä½¿ç”¨ CLIP:
```bash
pip install transformers protobuf
```

## æ–‡æ¡£ç´¢å¼• / Documentation Index

### åŸºç¡€å…¥é—¨ / Getting Started
- **[å¼€å§‹ä½¿ç”¨.md](å¼€å§‹ä½¿ç”¨.md)** - æœ¬æ–‡æ¡£ (5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹)
- **[è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md](è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md)** - å®Œæ•´ä¸­æ–‡æŒ‡å—

### æŠ€æœ¯æ–‡æ¡£ / Technical Docs
- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)** - å®Œæ•´è®­ç»ƒæŒ‡å— (è‹±æ–‡)
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - å¿«é€Ÿå‚è€ƒ (æµç¨‹å›¾)
- **[SEMANTIC_WATERMARKING.md](SEMANTIC_WATERMARKING.md)** - æ¶æ„æ–‡æ¡£

### ç¤ºä¾‹å’Œæ¼”ç¤º / Examples
- **[examples/README_TRAINING.md](examples/README_TRAINING.md)** - è®­ç»ƒç¤ºä¾‹
- **[examples/train_semantic_example.py](examples/train_semantic_example.py)** - æ¼”ç¤ºè„šæœ¬

### è¿ç§»å’Œå‚è€ƒ / Migration & Reference
- **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)** - ä»äºŒè¿›åˆ¶è¿ç§»
- **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** - å®ç°æ€»ç»“

## æ¨èå­¦ä¹ è·¯å¾„ / Recommended Learning Path

### è·¯å¾„ 1: å¿«é€Ÿå®è·µè€… (1å°æ—¶)
1. é˜…è¯»æœ¬æ–‡æ¡£ (5åˆ†é’Ÿ)
2. è¿è¡Œæµ‹è¯•å’Œæ¼”ç¤º (15åˆ†é’Ÿ)
   ```bash
   python examples/train_semantic_example.py --mode test_encoding
   python examples/train_semantic_example.py --mode demo_prompts
   python examples/train_semantic_example.py --mode train --use_sample_data
   ```
3. å‡†å¤‡æ•°æ®å¹¶å¼€å§‹è®­ç»ƒ (30åˆ†é’Ÿè®¾ç½® + è®­ç»ƒ)

### è·¯å¾„ 2: æ·±å…¥ç†è§£è€… (3å°æ—¶)
1. é˜…è¯»æœ¬æ–‡æ¡£ (5åˆ†é’Ÿ)
2. é˜…è¯» [è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md](è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md) (30åˆ†é’Ÿ)
3. æŸ¥çœ‹ [QUICK_REFERENCE.md](QUICK_REFERENCE.md) æµç¨‹å›¾ (15åˆ†é’Ÿ)
4. è¿è¡Œæ‰€æœ‰ç¤ºä¾‹å’Œæµ‹è¯• (30åˆ†é’Ÿ)
5. æ·±å…¥é˜…è¯» [SEMANTIC_WATERMARKING.md](SEMANTIC_WATERMARKING.md) (1å°æ—¶)
6. å¼€å§‹è®­ç»ƒå¹¶è°ƒæ•´å‚æ•° (30åˆ†é’Ÿ)

### è·¯å¾„ 3: ä»äºŒè¿›åˆ¶è¿ç§» (2å°æ—¶)
1. é˜…è¯» [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) (45åˆ†é’Ÿ)
2. æ›´æ–°é…ç½®æ–‡ä»¶ (15åˆ†é’Ÿ)
3. ä¿®æ”¹æ•°æ®åŠ è½½ä»£ç  (30åˆ†é’Ÿ)
4. æµ‹è¯•å’ŒéªŒè¯ (30åˆ†é’Ÿ)

## æ”¯æŒå’Œå¸®åŠ© / Support

### é‡åˆ°é—®é¢˜?

1. **æŸ¥çœ‹æ•…éšœæ’æŸ¥éƒ¨åˆ†** (æœ¬æ–‡æ¡£ä¸Šæ–¹)
2. **é˜…è¯»è®­ç»ƒæŒ‡å—çš„å¸¸è§é—®é¢˜** [è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md](è®­ç»ƒæŒ‡å—_ä¸­æ–‡.md)
3. **æŸ¥çœ‹å¿«é€Ÿå‚è€ƒçš„æ•…éšœæ’æŸ¥** [QUICK_REFERENCE.md](QUICK_REFERENCE.md)

### éœ€è¦å¸®åŠ©?

åœ¨ GitHub ä¸Šæäº¤ issueï¼ŒåŒ…æ‹¬:
- é”™è¯¯ä¿¡æ¯
- é…ç½®æ–‡ä»¶
- è®­ç»ƒå‘½ä»¤
- ç³»ç»Ÿç¯å¢ƒ

## ä¸‹ä¸€æ­¥ / Next Steps

å®Œæˆå¿«é€Ÿä¸Šæ‰‹å:

1. âœ… è¿è¡Œå®Œæ•´è®­ç»ƒ (40 epochs, ~30å°æ—¶)
2. âœ… ç›‘æ§è®­ç»ƒæŒ‡æ ‡
3. âœ… æµ‹è¯•æ°´å°é²æ£’æ€§
4. âœ… é›†æˆåˆ°ä½ çš„ T2I ç®¡é“
5. âœ… æ·»åŠ å…ƒæ•°æ® (æ¨¡å‹ç‰ˆæœ¬ã€ç”¨æˆ·IDç­‰)

## æ€»ç»“ / Summary

**æœ€ç®€å•çš„å¼€å§‹æ–¹å¼:**

```bash
# 1. æµ‹è¯• (1åˆ†é’Ÿ)
python examples/train_semantic_example.py --mode test_encoding

# 2. å‡†å¤‡æ•°æ® (åˆ›å»º train.csv)
# 3. è®­ç»ƒ (æ— éœ€è¯´æ˜æ–‡ä»¶)
python train.py --config configs/SD14_SemanticLaWa.yaml
```

**å°±è¿™ä¹ˆç®€å•ï¼ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†æç¤ºè¯ç”Ÿæˆå’Œæ–‡æœ¬èåˆã€‚**

æ¯å¼ å›¾ç‰‡å°†è·å¾—åŸºäºå…¶æç¤ºè¯çš„ç‹¬ç‰¹ã€å†…å®¹ç›¸å…³çš„è¯­ä¹‰æ°´å°ã€‚

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿä»ç¬¬ä¸€æ­¥å¼€å§‹å§ï¼** ğŸš€
